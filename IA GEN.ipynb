{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IA Generative Big Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creative Writing, Q&A, Text Summarization, Data Extraction,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We feed the model via the prompt the following elements :\n",
    "\n",
    "the instructions, \n",
    "\n",
    "external information / contexts (We do it manually, Web Search API), \n",
    "\n",
    "user input, \n",
    "\n",
    "output indicator (The start of what we would like the model to begin generating),\n",
    "\n",
    "... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with \"LangChain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain\n",
    "# ! pip install langchain_community\n",
    "# ! pip install langchain_ollama\n",
    "# ! pip install langchain_experimental\n",
    "# # ! pip install -U langchain-openai langchainhub\n",
    "# ! pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools = [PythonREPLTool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub, PromptTemplate\n",
    "from langchain.agents import create_openai_functions_agent, create_react_agent, AgentExecutor\n",
    "from langchain_community.chat_models import ChatAnthropic\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_experimental.tools import PythonREPLTool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Answer the question based on the context below. If the question cannot be answered using the information provided answer with \"I don't know\". \n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP. \n",
    "Their superior performance over smaller models has made them incredibly useful for developers building NLP enabled applications. \n",
    "These models can be accessed via Hugging Face's 'transformers' library, via OpenAI using the 'openai' library, and via Cohere using the 'cohere' library. \n",
    "\n",
    "Question: Which libraries and model providers offer LLMs? \n",
    "\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, so I need to figure out who Elon Musk's father is based on the information provided. Let me start by recalling what I know about Elon Musk.\n",
      "\n",
      "Elon Musk is a co-founder of Twitter and Tesla. He's been involved in many tech companies like SpaceX and Meta. Now, he mentioned that his father was a developer or someone interested in NLP. \n",
      "\n",
      "Looking at the context given, it's about Large Language Models (LLMs) being used in NLP, their access points via Hugging Face, OpenAI, or Cohere libraries. However, the question is specifically about Elon Musk's father's identity, which isn't directly related to his work as a developer or technology investor.\n",
      "\n",
      "The context doesn't provide any information about Elon Musk's family background. It only discusses his professional life and the tools he uses in NLP development. So, without additional context on his family members' roles or contributions, I can't determine who his father is based on this information.\n",
      "\n",
      "Therefore, I should state that I don't know because there isn't enough information provided about Elon Musk's family to answer the question.\n",
      "</think>\n",
      "\n",
      "I don't know\n"
     ]
    }
   ],
   "source": [
    "# instructions = \"\"\"You are an agent designed to write and execute python code to answer questions.\n",
    "# You have access to a python REPL, which you can use to execute python code.\n",
    "# If you get an error, debug your code and try again.\n",
    "# Only use the output of your code to answer the question. \n",
    "# You might know the answer without running any code, but you should still run the code to get the answer.\n",
    "# If it does not seem like you can write code to answer the question, just return \"I don't know\" as the answer.\n",
    "# \"\"\"\n",
    "\n",
    "prompt = \"\"\"Answer the question based on the context below. If the question cannot be answered using the information provided answer with \"I don't know\". \n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP. \n",
    "Their superior performance over smaller models has made them incredibly useful for developers building NLP enabled applications. \n",
    "These models can be accessed via Hugging Face's 'transformers' library, via OpenAI using the 'openai' library, and via Cohere using the 'cohere' library. \n",
    "\n",
    "Question: who is elon musk's father?\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt)\n",
    "model = OllamaLLM(model='deepseek-r1:1.5b') #\n",
    "chain = prompt | model\n",
    "\n",
    "response = chain.invoke({\"qestion\":\" Which one of the LLMs is the most efficient ?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_2756\\3701019134.py:27: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = model(prompt_template.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out which libraries and model providers offer large language models (LLMs). The context provided mentions that LLMs are a type of NLP model. It says that these models can be accessed via Hugging Face's 'transformers' library, OpenAI using the 'openai' library, and Cohere using the 'cohere' library. \n",
      "\n",
      "So, looking at that, I think each of those libraries is specifically for LLMs because they're all mentioned in relation to them. Hugging Face is a big deal in NLP, especially with Transformers. OpenAI's transformers are their core technology. And Cohere is another company known for AI tools and models. \n",
      "\n",
      "The question is asking which libraries and model providers offer LLMs. So I think the answer should list all these specific libraries because they're each dedicated to providing LLMs. There's no other information given about other libraries or model providers in that context, so I can't find more.\n",
      "</think>\n",
      "\n",
      "The libraries mentioned for accessing Large Language Models (LLMs) are Hugging Face's 'transformers' library, OpenAI's 'openai' library, and Cohere's 'cohere' library. These are the primary providers within their respective categories.\n",
      "\n",
      "Answer: The libraries are Hugging Face's 'transformers', OpenAI's 'openai', and Cohere's 'cohere'.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Answer the question based on the context below. If the question cannot be answered using the information provided answer with \"I don't know\". \n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP. \n",
    "Their superior performance over smaller models has made them incredibly useful for developers building NLP enabled applications. \n",
    "These models can be accessed via Hugging Face's 'transformers' library, via OpenAI using the 'openai' library, and via Cohere using the 'cohere' library. \n",
    "\n",
    "Question: {query}?\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = OllamaLLM(model='deepseek-r1:1.5b') #\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables = [\"query\"],\n",
    "    template = template\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "response = model(prompt_template.format(\n",
    "    query=\"Which libraries and model providers offer LLMs?\"\n",
    "))\n",
    "        \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"Docs/A Survey on Diffusion Models for Anomaly Detection.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Docs/A Survey on Diffusion Models for Anomaly Detection.pdf', 'page': 0}, page_content='A Survey on Diffusion Models for Anomaly Detection\\nJing Liu1,2 , Zhenchao Ma2 , Zepu Wang3 , Yang Liu1,3 , Zehua Wang2 ,\\nPeng Sun3 , Liang Song1 , Bo Hu1 , Azzedine Boukerche4 , Victor C.M. Leung2\\n1Fudan University, Shanghai, China\\n2University of British Columbia, Vancouver, Canada\\n3Duke Kunshan University, Suzhou, China\\n4University of Ottawa, Ottawa, Canada\\n{jingliu19, yang liu20, songl, bohu}@fudan.edu.cn, {zhenchaoma, zwang}@ece.ubc.ca,\\n{zw163, peng.sun568}@duke.edu, aboukerc@uottawa.ca, vleung@ieee.org\\nAbstract\\nDiffusion models (DMs) have emerged as a pow-\\nerful class of generative AI models, showing re-\\nmarkable potential in anomaly detection (AD) tasks\\nacross various domains, such as cybersecurity,\\nfraud detection, healthcare, and manufacturing.\\nThe intersection of these two fields, termed diffu-\\nsion models for anomaly detection (DMAD), offers\\npromising solutions for identifying deviations in in-\\ncreasingly complex and high-dimensional data. In\\nthis survey, we review recent advances in DMAD\\nresearch. We begin by presenting the funda-\\nmental concepts of AD and DMs, followed by a\\ncomprehensive analysis of classic DM architec-\\ntures including DDPMs, DDIMs, and Score SDEs.\\nWe further categorize existing DMAD methods\\ninto reconstruction-based, density-based, and hy-\\nbrid approaches, providing detailed examinations\\nof their methodological innovations. We also ex-\\nplore the diverse tasks across different data modal-\\nities, encompassing image, time series, video, and\\nmultimodal data analysis. Furthermore, we discuss\\ncritical challenges and emerging research direc-\\ntions, including computational efficiency, model in-\\nterpretability, robustness enhancement, edge-cloud\\ncollaboration, and integration with large language\\nmodels. The collection of DMAD research papers\\nand resources is available at https://github.\\ncom/fdjingliu/DMAD.\\n1 Introduction\\nThe ever-increasing volume, velocity, and variety of data\\npresent both opportunities and challenges for anomaly detec-\\ntion (AD). In cybersecurity, real-time threat detection is cru-\\ncial given the constant influx of network traffic and logs [Jin\\net al., 2024]. Similarly, robust fraud detection systems are\\nessential for financial institutions processing massive trans-\\naction datasets [Wang et al., 2023a]. Healthcare and man-\\nufacturing also rely heavily on data for early disease diag-\\nnosis and predictive maintenance, respectively [Zhang et al.,\\n2023]. Such applications highlight the growing need for au-\\ntomated AD methods to efficiently identify outliers in com-\\nplex datasets. However, traditional techniques, often based\\non statistical methods or rule-based systems, struggle with\\nthe scale and complexity of modern data [Katsuoka et al.,\\n2024]. Specifically, these methods often require extensive\\nmanual feature engineering and struggle to adapt to evolv-\\ning data distributions. Additionally, the sheer data volume\\ncan overwhelm traditional methods, rendering them compu-\\ntationally infeasible for real-time applications. Consequently,\\nmore sophisticated and scalable AD approaches are needed.\\nFor example, weakly supervised approaches leverage limited\\nlabeled data to improve performance[Pang et al., 2021], driv-\\ning innovation toward scalable deep learning architectures\\nthat address these fundamental challenges.\\nDiffusion models (DMs) have emerged as a powerful class\\nof generative models, synthesizing samples across diverse\\ndata modalities [Wang et al., 2023c ]. Unlike generative\\nadversarial networks (GANs) and variational autoencoders\\n(V AEs), which may exhibit training instability or produce less\\ndetailed samples [Dao et al., 2024 ], DMs generate sharper,\\nmore realistic samples through a gradual denoising process\\n[Chen et al., 2024b ]. Consequently, DMs excel in captur-\\ning a broader range of data distributions compared to GANs\\n[Wyatt et al., 2022 ], making them particularly suitable for\\nanomaly detection, where their enhanced mode coverage fa-\\ncilitates precise modeling of normal patterns and subsequent\\nidentification of distributional outliers [Li et al., 2024].\\nRecent growth in complex and multi-dimensional data has\\ncreated new challenges for anomaly detection methods. In\\nthis context, DMs have emerged as a promising solution due\\nto their inherent connection to density estimation[Le Lan and\\nDinh, 2021]. DMs learn the probability distributions of nor-\\nmal data through iterative denoising. Leveraging their excep-\\ntional generative abilities, DMs accurately reconstruct normal\\npatterns while capturing underlying manifold structures, en-\\nabling anomaly detection through reconstruction error anal-\\nysis and probability density estimation [Hu and Jin, 2023 ].\\nFor example, AnoDDPM [Wyatt et al., 2022] uses diffusion\\nmodels for anomaly detection via reconstruction error, and\\nODD [Wang et al., 2023b ] enhances this by leveraging ad-\\nvanced generative modeling for high-dimensional data. Ad-\\nditionally, the learned score function, representing the gradi-\\narXiv:2501.11430v3  [cs.LG]  24 Jan 2025'),\n",
       " Document(metadata={'source': 'Docs/A Survey on Diffusion Models for Anomaly Detection.pdf', 'page': 1}, page_content='DMAD\\nMethodologies(Decision Logic)\\nTasks\\n(Data modalities)\\nReconstruction-based\\nDensity-based\\nHybrid\\nImage DMAD\\nTime Series DMAD\\nBasic Reconstruction\\nLatent Space\\nReconstruction \\nVideo DMAD\\nMultimodal DMAD\\nConditional \\nReconstruction\\nScore Function  as \\nAnomaly Score\\nDiffusion Time\\nEstimation\\nTaxonomy of DMAD\\nGitHub\\nDatasets\\nMetrics\\nCodesLiteratures\\nChallenges\\nDirections\\nDissusions\\nFigure 1: Taxonomy of diffusion models for anomaly detection.\\nent of the log-probability density, can be directly used as an\\nanomaly score, as demonstrated in diffusion time estimation\\n[Livernoche et al., 2023].\\nMotivations. While existing surveys have separately re-\\nviewed anomaly detection [Jin et al., 2024; Pang et al., 2021]\\nand diffusion models [Yang et al., 2024b; Luo, 2023 ], they\\neither focus on traditional deep learning approaches without\\nconsidering the emerging role of diffusion models, or treat\\nanomaly detection merely as one of many DM applications\\nwithout in-depth analysis. Recent breakthroughs in diffusion\\nmodels for anomaly detection (DMAD) demonstrate remark-\\nable potential to revolutionize the field through their unique\\ncapabilities in modeling complex data distributions and gen-\\nerating high-quality samples. Despite these advances, there is\\nno existing work has systematically reviewed how DMs en-\\nhance anomaly detection or analyzed their emerging role at\\nthe intersection of both domains. Our work addresses this\\ngap by providing a timely overview of DMAD, analyzing its\\ntheoretical foundations, current achievements, and promising\\nfuture directions that could fundamentally reshape the land-\\nscape of anomaly detection research.\\nContributions. The main contributions of this survey are\\nfour-fold: (1) A systematic taxonomy. We present the first\\ncomprehensive taxonomy of DMAD (as shown in Fig. 1), cat-\\negorizing existing methodologies into reconstruction-based,\\ndensity-based, and hybrid methods, providing a structured\\nframework for understanding this emerging field. (2) A com-\\nprehensive review. Based on the proposed taxonomy, we\\nsystematically analyze DMAD across different tasks, includ-\\ning image anomaly detection (IAD), time series anomaly\\ndetection (TSAD), video anomaly detection (V AD), and\\nmultimodal anomaly detection (MAD), discussing their ap-\\nproaches, strengths, and limitations. (3) Technical chal-\\nlenges and future directions. We identify and discuss criti-\\ncal challenges in DMAD, including computational costs, in-\\nterpretability, robustness against adversarial attacks, complex\\ndata distributions, edge-cloud collaboration, and integration\\nwith large language models (LLMs), while suggesting poten-\\ntial solutions and future research directions. (4) Resources\\nand benchmarks. We provide a thorough collection of repre-\\nsentative methods, implementations, datasets, and evaluation\\nmetrics for different tasks, serving as a valuable resource for\\nresearchers and practitioners in this field.\\n2 Preliminaries\\nThis section begins by providing the fundamental concepts of\\nanomaly detection. Following this, we introduce the various\\ntypes of anomalies, including point, contextual, and collec-\\ntive anomalies. Next, we discuss the basic principles of DMs\\nand their relevance to anomaly detection. We then explore\\nscore-based models and score matching techniques. Finally,\\nwe present prominent variants of DMs used in anomaly de-\\ntection, highlighting their advantages and disadvantages.\\n2.1 Anomaly Detection\\nAnomaly detection aims to identify instances deviating sig-\\nnificantly from the expected data distribution[Wang and Vas-\\ntola, 2023 ]. Given a dataset D = {x1, x2, ..., xn}, where\\nxi ∈ Rd, the goal is to identify the anomalous subset A ⊂\\nD. Anomalous behavior is characterized by low probability\\ndensity under the typically unknown distribution p(x). Sev-\\neral anomaly types exist, including point anomalies [Hu and\\nJin, 2023 ] that are individual deviant instances; contextual\\nanomalies [Sui et al., 2024] that are anomalous within a spe-\\ncific context; and collective anomalies that are groups of in-\\nstances anomalous only when considered together. Com-\\nmon evaluation metrics include AUC [Xu et al., 2023], mea-\\nsuring the classifier’s ability to distinguish between normal\\nand anomalous instances. Additionally, precision, recall,\\nand F1-score assess the trade-off between correct identifi-\\ncation and minimizing false alarms [Wang et al., 2023a;\\nXiao et al., 2023; Zuo et al., 2024]. The choice of metric de-\\npends on the application and the relative importance of mini-\\nmizing false positives and negatives [Pang et al., 2021].\\n2.2 Diffusion Models\\nDMs constitute a class of latent variable models defined by\\nforward and reverse Markov processes to corrupt and denoise\\ndata, with training based on the variational lower bound of\\nthe negative log-likelihood.\\nForward Process. Forward process is known as the dif-\\nfusion process, gradually adds noise to data x0 over T\\ntimesteps, transforming its distribution into an isotropic\\nGaussian. Specifically, given a variance schedule {βt}T\\nt=1,\\nwhere 0 < β1 < ··· < βT < 1, the process generates se-\\nquence of latent variables {x1, . . . , xT } via a Markov chain\\nwith the Gaussian transition kernel:\\nq(xt|xt−1) = N(xt;\\np\\n1 − βtxt−1, βtI). (1)\\nHere, N(x; µ, Σ) denotes a Gaussian distribution with mean\\nµ and covariance Σ, and I is the identity matrix. The param-\\neter βt controls the noise added at each step. As t increases,\\nxT approaches Gaussian noise. Due to the Markov property,\\nthe joint distribution is:\\nq(x1:T |x0) =\\nTY\\nt=1\\nq(xt|xt−1). (2)\\nConsequently, any xt can be directly sampled from x0:\\nq(xt|x0) = N(xt; √¯αtx0, (1 − ¯αt)I), (3)'),\n",
       " Document(metadata={'source': 'Docs/A Survey on Diffusion Models for Anomaly Detection.pdf', 'page': 2}, page_content='where αt = 1 − βt and ¯αt = Qt\\ni=1 αi, which provides\\ncomputational benefits. Related work explores this pro-\\ncess through various perspectives, including multiplicative\\ntransitions, uniformization techniques for convergence anal-\\nysis, Gaussian process covariance transformations, tensor\\nnetwork modeling, first-passage time statistics, and infinite-\\ndimensional diffusion processes [Kumar et al., 2023].\\nReverse Process. Reverse process aims to learn the con-\\nditional probability distribution pθ(xt−1|xt) to recover the\\noriginal data distribution by iteratively removing noise. It\\nis typically modeled as a Gaussian distribution:\\npθ(xt−1|xt) = N(xt−1; µθ(xt, t), Σθ(xt, t)), (4)\\nwhere µθ and Σθ are the predicted mean and covariance, re-\\nspectively, parameterized by a neural network (e.g., U-Net\\n[Yan et al., 2024 ] or Transformer [Cao et al., 2024 ]) and\\nconditioned on the noisy input xt at timestep t. While\\nthe covariance Σθ(xt, t) can be learned, a common simpli-\\nfication is to use a fixed, time-dependent variance [Salimans\\nand Ho, 2021 ]. The neural network learns to predict the\\nmean µθ(xt, t), which guides denoising. Several parame-\\nterization strategies exist, including predicting the mean of\\nq(xt−1|xt, x0), added noise ϵt, or original data x0. Starting\\nfrom Gaussian noise xT , the reverse process iteratively ap-\\nplies pθ(xt−1|xt) until x0 is reached.\\nTraining Objective. DMs are trained by maximizing the\\nlikelihood of observed data. However, due to the latent\\nvariable formulation, direct optimization is intractable. Con-\\nsequently, training relies on maximizing a variational lower\\nbound (VLB) of the data log-likelihood, derived using varia-\\ntional inference [Bercea et al., 2023] as:\\nLvlb =Eq[DKL(q(xT |x0)||pθ(xT ))] − log pθ(x0|x1)\\n+Eq[\\nTX\\nt=2\\nDKL(q(xt−1|xt, x0)||pθ(xt−1|xt))], (5)\\nwhere q and pθ denote the forward and learned reverse pro-\\ncess distributions, respectively. Here, DKL is the Kullback-\\nLeibler divergence, x0 represents the original data, and xt is\\nthe noisy sample at timestep t. A simplified objective mini-\\nmizes the L2 distance between true and predicted noise [Han\\net al., 2024b], can be expressed as:\\nLsimple =\\nTX\\nt=1\\nEq\\n\\x02\\n||ϵt − ϵθ(xt, t)||2\\x03\\n, (6)\\nwhere ϵt and ϵθ(xt, t) denote the true and predicted noise, re-\\nspectively. Such simplified objective exhibits computational\\nefficiency and effectiveness [Livernoche et al., 2023]. Addi-\\ntionally, weighting loss terms at different timesteps can im-\\nprove performance [Choi et al., 2022 ]. From another per-\\nspective, DMs can be viewed as distribution estimators with\\ntheoretical guarantees, and the training objective can be based\\non score matching, where the model estimates the score func-\\ntion [Zhang and Pilanci, 2024 ]. A unified framework for\\ndiscrete and continuous-time DMs offers further insights into\\nobjective optimization [Lee et al., 2023a].\\n2.3 Score-based Models and Score Matching\\nScore Matching for Learning Score Functions. Score-\\nbased generative models learn the score function∇x log p(x),\\nrepresenting the gradient of the log-probability density. By\\nencoding distributional characteristics directly through these\\ngradients, score functions enable powerful generative capa-\\nbilities without explicit density estimation. Score matching\\noffers a practical way to learn this score function without\\nneeding p(x) explicitly. Instead, it minimizes the Fisher di-\\nvergence between the learned and true score functions [Han\\net al., 2024b]. Specifically, the score matching objective is\\nLSM (θ) = 1\\n2 Ep(x)\\n\\x02\\n∥∇x log pθ(x) − ∇x log p(x)∥2\\x03\\n.\\nDenoising Score Matching. However, computing the true\\nscore is often intractable. Consequently, denoising score\\nmatching perturbs data with Gaussian noise and learning the\\nscore of this perturbed distribution. The objective becomes\\nLDSM (θ) = 1\\n2 Eqσ(x)\\n\\x02\\n∥∇x log pθ(x) − ∇x log qσ(x)∥2\\x03\\n,\\nwhere qσ(x) is the perturbed distribution. Learning scores\\nat various noise levels allows DMs to capture the data distri-\\nbution at different scales [Wang et al., 2023d].\\nAdvanced Techniques. Recent research highlights the in-\\nherent linear structure within score-based models, particu-\\nlarly at higher noise levels, potentially accelerating sampling\\n[Wang and Vastola, 2023]. Prioritizing specific noise levels\\nduring training, based on perceptual relevance, can further\\nimprove performance [Choi et al., 2022]. In addition, gra-\\ndient guidance, incorporating an external objective function’s\\ngradient during sampling, adapts pre-trained models to spe-\\ncific tasks [Tur et al., 2023b].\\n2.4 Variants of Diffusion Models\\nIn this section, we discuss prominent diffusion model vari-\\nants for anomaly detection, including denoising diffusion\\nprobabilistic models (DDPMs), denoising diffusion implicit\\nmodels (DDIMs), and score-based generative models with\\nstochastic differential equations (Score SDEs), along with\\ntheir advantages and disadvantages.\\nDDPMs. DDPMs [Bercea et al., 2023] progressively intro-\\nduce Gaussian noise to the data across multiple time steps us-\\ning a Markov chain. A trained neural network then reverses\\nthis process, enabling the model to effectively learn com-\\nplex distributions, which makes it particularly well-suited for\\nanomaly detection [Wyatt et al., 2022]. However, generating\\nsamples can be computationally expensive.\\nDDIMs. DDIMs [Xu et al., 2023 ] extend DDPMs with a\\nnon-Markovian sampling approach, enabling faster genera-\\ntion by skipping steps. Specifically, they modify the reverse\\nprocess, and by setting a specific parameter to zero, DDIMs\\nallow deterministic sampling, beneficial for consistent recon-\\nstructions in anomaly detection [Tebbe and Tayyub, 2024].\\nScore SDEs. Score SDEs [Deveney et al., 2023] model dif-\\nfusion as a continuous-time SDE, where the score function,\\nrepresenting the gradient of the log-probability density, can\\nbe used for anomaly scoring [Li et al., 2024]. While offer-\\ning flexibility for complex distributions [Livernoche et al.,\\n2023], training and parameterization choices can be challeng-\\ning [Graham et al., 2023].'),\n",
       " Document(metadata={'source': 'Docs/A Survey on Diffusion Models for Anomaly Detection.pdf', 'page': 3}, page_content='Score\\nForward Reverse\\nsteps steps\\n(a) Basic reconstruction\\nScore\\nForward Reverse\\nsteps steps\\n(b) Latent space reconstruction\\nDecoder\\nScore\\nForward Reverse\\nsteps steps\\n(c) Conditional reconstruction\\nEncoder\\nFigure 2: Pipeline illustration of reconstruction-based AD methods:\\n(a) basic, (b) latent space, and (c) conditional reconstruction.\\n3 Methodologies\\n3.1 Reconstruction-based Anomaly Detection\\nReconstruction-based AD (RAD) leverages DMs to iden-\\ntify deviations from learned data distributions. Within this\\nparadigm, we consider three reconstruction strategies, as il-\\nlustrated in Fig. 2: 1) basic reconstruction, where reconstruc-\\ntion error serves as the anomaly score; 2) latent space re-\\nconstruction, incorporating dimensionality reduction for effi-\\nciency with high-dimensional data; 3) conditional reconstruc-\\ntion, leveraging auxiliary information like class labels for po-\\ntentially more refined anomaly detection.\\nBasic Reconstruction. RAD hinges on the principle that\\nDMs trained on normal data reconstruct normal instances\\neffectively, but struggle with anomalous ones [Hu and Jin,\\n2023]. Specifically, after training on normal samples, the\\nmodel reconstructs a test sample by reversing the diffusion\\nprocess. The difference between the input and its reconstruc-\\ntion constitutes the anomaly score [Zhang et al., 2023 ]. A\\nhigher score indicates a greater likelihood of an anomaly. For\\ninstance, GLAD [Yao et al., 2025] employs global and local\\nreconstruction perspectives. In contrast, AutoDDPM [Bercea\\net al., 2023] focuses on improving normal region reconstruc-\\ntion. Alternatively, some approaches use a learned similarity\\nnetwork for comparison, yielding a semantic distance as the\\nanomaly score [Wang et al., 2023b].\\nLatent Space Reconstruction. RAD leverages latent space\\nrepresentations for enhanced efficiency and effective han-\\ndling of high-dimensional data, such as images or videos.\\nSpecifically, projecting input data into a lower-dimensional\\nlatent space significantly reduces the computational burden\\nassociated with reconstruction. Autoencoders (AEs) are com-\\nmonly employed for this dimensionality reduction, which\\nlearns a compressed representation by encoding data into a\\nlatent space and then decoding it back to the original space.\\nIntegrating AEs with DMs offers a promising approach. For\\nexample, DMs trained on AEs-learned latent representations\\ncan capture the normal data distribution in the compressed\\nspace [Hu and Jin, 2023 ]. In addition, NGLS-Diff [Han et\\nal., 2024a ] is a novel approach that utilizes DMs within a\\nnormal gathering latent space to enhance anomaly detection\\ncapabilities for time series data. The latent space reconstruc-\\ntion error then serves as an anomaly score, with deviations\\nindicating potential anomalies [Wang et al., 2023c]. Shared\\nlatent spaces across multiple AEs can separate treatment and\\ncontext. Similarly, supervised dimensionality reduction can\\noptimize the latent space for specific classification tasks, and\\nemploying Brownian motion within Diffusion V AEs captures\\ndataset topology [Le Lan and Dinh, 2021].\\nConditional Reconstruction. Conditional information,\\nsuch as class labels, masks, or text descriptions, guides the\\ndiffusion model’s reconstruction toward expected normal\\noutputs. For example, FDAE [Zhu et al., 2024 ] utilizes\\nforeground objects and motion information as inputs to\\ntrain a conditional diffusion autoencoder, enhancing the\\ndetection of anomalous regions in an unsupervised manner.\\nDual conditioning [Zhan et al., 2024 ] improves multi-class\\nanomaly detection by ensuring prediction and reconstruction\\naccuracy within the expected category. A learnable encoder\\nin RecDMs [Xu et al., 2023 ] extracts semantic representa-\\ntions for conditional denoising, thus guiding recovery and\\navoiding trivial reconstructions. Similarly, GLAD [Yao et\\nal., 2025] introduces synthetic anomalies during training to\\nencourage the model to learn complex noise distributions for\\nimproved anomaly-free reconstruction. In addition, [Tebbe\\nand Tayyub, 2024] explores dynamic step size computation\\nbased on initial anomaly predictions for refined reconstruc-\\ntion. Finally, MDPS [Wu et al., 2024] models normal image\\nreconstruction as multiple diffusion posterior sampling using\\na masked noisy observation model and a diffusion-based\\nprior, consequently improving reconstruction quality.\\n3.2 Density-based Anomaly Detection\\nThis section considers two primary methods for density-\\nbased AD (DAD), as shown in Fig. 3: Score function and\\ndiffusion time estimation (DTE), illustrated by their use of\\nthe learned probability density to identify outliers.\\nScore Function as Anomaly Score. Gradient-based log\\nprobability density score functions, ∥∇x log p(x)∥, accu-\\nrately and effectively quantify data point likelihoods within\\nlearned distributions [Zhang and Pilanci, 2024]. Within low-\\ndensity regions, higher score magnitudes reliably indicate po-\\ntential anomalies by leveraging the score network sθ(xt, t)\\n[Livernoche et al., 2023 ]. Additionally, probability density\\ncharacterization through score computation enables direct\\nanomaly assessment without requiring explicit reconstruc-\\ntion or comparative analysis. Theoretical foundations estab-\\nlished by [Wang and Vastola, 2023] and [Han et al., 2024b]'),\n",
       " Document(metadata={'source': 'Docs/A Survey on Diffusion Models for Anomaly Detection.pdf', 'page': 4}, page_content='Forward Score Network\\nsteps\\n(a) Score function as anomaly score\\nScore\\n(b) Diffusion time estimation\\nTime EstimationNetwork TimeDistribution Score\\nFigure 3: Pipeline illustration of density-based AD methods: (a)\\nscore function-based and (b) diffusion time estimation method.\\nstrongly validate this methodology, although recent investi-\\ngations [Deveney et al., 2023] illuminate potential disparities\\nbetween SDE and ODE formulations, warranting careful con-\\nsideration in score-based anomaly detection frameworks.\\nDiffusion Time Estimation. DTE offers an alternative\\nanomaly detection method leveraging the diffusion process\\n[Livernoche et al., 2023]. Instead of reconstructing the input\\nx, DTE estimates the diffusion timestep tdiff required for\\nx to traverse the data distribution pdata(x). The estimation\\nis performed by a time estimation network, which predicts\\nthe time distribution. Intuitively, a longer tdiff suggests an\\nanomaly due to the x’s distance from the learned distribution\\n[Luo, 2023]. The estimated diffusion time tdiff thus serves\\nas an anomaly score, derived from the mode or mean of its\\ndistribution. An analytical form for this density is derivable,\\nand deep neural networks can improve inference efficiency.\\nConsequently, DTE has shown competitive performance, es-\\npecially in speed, on benchmarks like ADBench, while main-\\ntaining or exceeding the accuracy of traditional DDPMs.\\n3.3 Hybrid Approaches\\nHybrid approaches integrate DMs with other anomaly detec-\\ntion techniques to improve performance. For example, RAD\\ncan be combined with density estimation, where reconstruc-\\ntion error from DMs is integrated with DAD, like DTE[Liver-\\nnoche et al., 2023]. Additionally, dynamic step size computa-\\ntion in the forward process, guided by initial anomaly predic-\\ntions, improves performance by denoising scaled input with-\\nout added noise [Tebbe and Tayyub, 2024 ]. In another ap-\\nproach, likelihood maps of potential anomalies from DMs are\\nintegrated with the original image via joint noised distribution\\nre-sampling, enhancing healthy tissue restoration [Bercea et\\nal., 2023]. For TSAD, hybrid methods can employ density\\nratio-based strategies to select normal observations for im-\\nputation, combined with denoising diffusion-based imputa-\\ntion to improve missing value generation, especially under\\nanomaly concentration [Xiao et al., 2023]. Advanced recon-\\nstruction techniques predict specific denoising steps by ana-\\nlyzing divergences between image and diffusion model pri-\\nors, supplemented by synthetic abnormal sample generation\\nduring training and spatial-adaptive feature fusion during in-\\nference [Yao et al., 2025]. Integrating DMs with Transform-\\ners for multi-class anomaly detection, where diffusion pro-\\nMethod DS Datasets Results of metrics on datasets\\nFNDM[2023] D BRATS, ISLES Dice: 76.21% (BRATS), 54.44%\\n(ISLES), VS: 82.28% (BRATS), etc.\\nODD[2023b] D MNIST, CIFAR-10,\\netc.\\nAUROC: 97.8% (MNIST), 84.7%\\n(CIFAR-10), etc.\\nmDDPM[2024] D BraTS21, MSLUBDice: 53.02% (BraTS21), 10.71%\\n(MSLUB), etc.\\nDif-fuse[2024] D IST-3, BraTS, WMHDice: 0.699 (BraTS21), 0.569\\n(WMH), etc.\\nDIC[2024] C VisA, BTAD,\\nMVTec\\nI-AUROC: 96.0%, P-AUROC:\\n97.9%, PRO 94.1% on VisA, etc.\\nDRAD[2024] C MVTec-AD I-AUROC: 99.1% (MVTec-AD), P-\\nAUROC: 97.3% (MVTec-AD), etc.\\nMDPS[2024] C MVTec-AD, BTADI-AUROC: 98.4% (MVTec-AD), P-\\nAUROC: 97.0% (MVTec-AD), etc.\\nDISYRE[2024] C CamCAN, ATLAS,\\nBraTS\\nAP: 0.45 (ATLAS), 0.51 (BraTS-T1),\\n0.73 (BraTS-T2), etc.\\nNotes: Method highlighted in blue indicates available open-source code\\nlinks. DS denotes diffusion space, where ’D’ is discrete and ’C’ is contin-\\nuous. Due to space limitations, only partial datasets and results are shown.\\nFor more details, please find our GitHub.\\nTable 1: Summary of IAD methods with metric results on datasets.\\nvides high-frequency information for refinement, mitigates\\nblurry reconstruction and ”identical shortcuts” [Zhan et al.,\\n2024]. Finally, a Bayesian framework employing masked\\nnoisy observation models and diffusion-based normal im-\\nage priors enables effective difference map computation be-\\ntween normal posterior samples and the test image, improv-\\ning anomaly detection and localization [Wu et al., 2024].\\n4 Tasks\\nIn this section, we consider four primary tasks of DMAD,\\nas summarized in Tables 1-4, which present representative\\nmethods with open-source implementations, datasets, evalu-\\nation metrics, and corresponding results. For each task, meth-\\nods are categorized based on their underlying principles and\\ndetection strategies, highlighting the unique challenges and\\nsolutions developed for different data modalities.\\n4.1 Image Anomaly Detection\\nIAD represents a key application area for DMs, focusing\\non identifying deviations from normality in both global pat-\\nterns affecting entire images and local anomalies confined\\nto specific regions. Many approaches leverage DMs’ re-\\nconstruction capabilities, with methods calculating anomaly\\nscores from reconstruction errors after reconstructing im-\\nages from noisy inputs [Xu et al., 2023; Tur et al., 2023a;\\nWang et al., 2023d]. Advanced frameworks like GLAD [Yao\\net al., 2025 ] employ global and local adaptive approaches,\\nwhile ODD [Wang et al., 2023b ] introduces similarity net-\\nworks for semantic distance measurement. Medical imag-\\ning applications have shown particular promise, with FNDM\\n[Li et al., 2023 ] and mDDPM [Iqbal et al., 2024 ] demon-\\nstrating enhanced efficiency through masked diffusion mod-\\nels, while [Fontanella et al., 2024 ] introduces novel coun-\\nterfactual generation techniques. Recent research includes\\nAnomalyDiffusion [Hu et al., 2024b] for few-shot generation\\nand [Naval Marimont et al., 2024]’s cold-diffusion approach.\\nMDPS [Wu et al., 2024] and DRAD [Sheng et al., 2024] fur-\\nther enhance detection through masked sampling and noise\\nembedding, while methods like [Tebbe and Tayyub, 2024 ]'),\n",
       " Document(metadata={'source': 'Docs/A Survey on Diffusion Models for Anomaly Detection.pdf', 'page': 5}, page_content='Method DS Datasets Results of metrics on datasets\\nSimpDM[2024b] C Iris, Yacht, etc. RMSE: 0.059 (Iris), 0.045 (Yacht),\\n0.102 (Housing), etc.\\nCoDi[2023a] C & DBank, Heart, etc.B-F1: 0.4726, B-AUROC: 0.8106,\\nM-F1: 0.62211, etc., on Bank\\nTimeDiT[2024] C Stocks, Energy, ect.DS: 0.115 (Stocks), 0.1778 (Air Qual-\\nity), 0.1726 (Energy), etc.\\nNGLS-Diff[2024a] C SWaT, MSL, etc.F1: 97.52% (SWaT), 90.81% (MSL),\\n95.30% (SMAP), 98.04% (PSM)\\nD3R[2023a] C PSM, SMD, SWaTF1: 76.09% (PSM), 86.82% (SMD),\\n78.12% (SWaT)\\nDiffAD[2023] C MSL, SWaT, etc.F1: 94.19% (MSL), 97.66% (SWaT),\\n97.95% (PSM), 96.95% (SMAP), etc.\\nDiffADT[2024] C SMAP, MSL, SMDPre: 96.33% (SMAP), 95.21%\\n(MSL), 79.87% (SMD), etc.\\nTable 2: Summary of TSAD methods with metric results on datasets.\\nMethod DS Datasets Results of metrics on datasets\\nMoCoDAD[2023] D UB, HR-STC, etc.AUC: 77.6% (HR-STC), 89.0% (HR-\\nAve), 68.4% (HR-UB), 68.3% (UB)[Turet al., 2023b] D UCF, ShT AUC: 76.36% (ShT), 63.67% (UCF)\\nDHV AD[2024] C Ped2, Ave, ShT AUC: 98.1% (Ped2), 88.3% (Ave),\\n78.9% (ShT)\\nFDAE[2024] D Ave, ShT, Ped2 AUC: 97.7% (Ped2), 91.1% (Ave),\\n73.8% (ShT)\\nMasked Diffusion[2023] D CrossTask,NIV ,COINSR: 39.17% (CrossTask), 32.35%\\n(NIV), 29.43% (COIN), etc.\\nFPDM[2023] D Ave, ShT, UCF, UBAUC: 90.1% (Ave), 78.6% (ShT),\\n74.7% (UCF), 62.7% (UB)[Wang et al.,\\n2023d] D Ped2, Ave, ShT AUC: 96.5% (Ped2), 92.2% (Ave),\\n75.4% (ShT)\\nDiffV AD[2024] D Ave, ShT, UCF, etc.AUC: 81.9% (ShT), 90.3% (Ave),\\n87.6% (Ped2), etc.\\nMasked Diffusion[2023] C CrossTask,NIV ,COINSR: 39.17% (CrossTask), 23.47%\\n(CrossTask), 32.35% (NIV), etc.\\nV ADiffusion[2024a] D Ped2, Ave, ShT AUC: 98.2% (Ped2), 94.93% (Ave),\\n97.32% (ShT)\\nTable 3: Summary of V AD methods with metric results on datasets.\\nemploy dynamic step size computation to improve localiza-\\ntion accuracy.\\n4.2 Time Series Anomaly Detection\\nDMs have emerged as a powerful technique for TSAD, ef-\\nfectively learning complex distributions of sequential data\\n[Yang et al., 2024b ]. DMs can identify various anomaly\\ntypes, including point, contextual, and collective anomalies\\n[Sui et al., 2024 ]. Advanced approaches like NGLS-Diff\\n[Han et al., 2024a ] leverage latent spaces, while methods\\n[Zuo et al., 2024] used structured state space layers explic-\\nitly to model temporal dependencies. Recently, some innova-\\ntions address key challenges: D3R [Wang et al., 2023a] tack-\\nles non-stationarity through dynamic decomposition, while\\nTimeDiT [Cao et al., 2024 ] introduces a foundation model\\napproach with multiple masking schemes. Another key chal-\\nlenge is non-stationarity. DiffAD [Xiao et al., 2023 ] han-\\ndle missing data through imputation, complemented by self-\\nsupervised techniques [Liu et al., 2024b ] and co-evolving\\nstrategies [Lee et al., 2023a] for mixed-type temporal data.\\n4.3 Video Anomaly Detection\\nV AD effectively leverages spatio-temporal information to\\nidentify unusual events. DMs have emerged as a highly\\npromising V AD approach due to their ability to learn com-\\nplex data distributions and generate high-quality reconstruc-\\ntions. For example, [Tur et al., 2023a ] investigated unsu-\\nMethod Mods.DS Datasets Results of metrics on datasets\\nMPDR[2023] I, V , AC MNIST, CIFAR-10,etc. AUPR: 0.764 (MNIST), 0.9860 (CIFAR-10), 0.8338 (CIFAR-100), etc.DIAG[2024] I, T C KSDD2 AP: 80.1% (zero-shot), 92.4% (full-shot)AnomalyXFusion[2024a] I, T, TeC MVTec-AD, MVTecLOCO IS: 1.82, IC-LPIPS: 0.33\\nNotes: Mods. indicates modalities, where ’I’ is image, ’V’ is vector, ’A’ is\\naudio, ’T’ is text, and ’Te’ is texture.\\nTable 4: Summary of MAD methods with metric results on datasets.\\npervised V AD using DMs, relying on high reconstruction\\nerror to indicate anomalies, while [Tur et al., 2023b ] en-\\nhanced this approach by introducing compact motion repre-\\nsentations as conditional information. Several innovative ar-\\nchitectures have been recently proposed to improve detection\\naccuracy: V ADiffusion [Liu et al., 2024a ] employs a dual-\\nbranch structure combining motion vector reconstruction and\\nI-frame prediction, while FDAE [Zhu et al., 2024] introduces\\na flow-guided diffusion autoencoder with sample refinement\\nfor comprehensive detection of both appearance and motion\\nanomalies. Recent advances include [Yan et al., 2023]’s fea-\\nture prediction diffusion model and[Cheng et al., 2024]’s de-\\nnoising diffusion-augmented hybrid framework, both enhanc-\\ning semantic understanding of normal patterns. Furthermore,\\n[Wang et al., 2023d] proposed an ensemble approach using\\nstochastic reconstructions and motion filters, while [Fang et\\nal., 2023] explored masked diffusion with task-awareness for\\nmore focused anomaly detection in specific contexts.\\n4.4 Multimodal Anomaly Detection\\nMAD integrates data from various sources to identify devi-\\nations from expected behavior. While DMs are relatively\\nnascent in this area, they hold substantial promise through\\nadvanced multimodal data integration. For instance, Anoma-\\nlyXFusion [Hu et al., 2024a] enhances anomaly synthesis by\\neffectively combining image, text, and mask features, while\\n[Flaborea et al., 2023 ] demonstrates significant success in\\nskeleton-based V AD through motion-conditioned diffusion\\nmodels. For IAD, combining visual data with text descrip-\\ntions significantly improves subtle anomaly detection [Ca-\\npogrosso et al., 2024], with energy-based approaches [Yoon\\net al., 2023 ] leveraging manifold structures for more accu-\\nrate boundary learning. GLAD [Yao et al., 2025] further sug-\\ngests extending DMs for multimodal data through specialized\\narchitectures, while integration with LLMs offers promising\\ndirections for context-aware anomaly detection.\\n5 Discussions\\nDespite significant progress in DMAD, several critical chal-\\nlenges remain. In this section, we explore key areas that re-\\nquire further research and development.\\nComputational Cost. Widespread adoption of DMAD re-\\nmains constrained by substantial computational require-\\nments, particularly when processing high-dimensional data\\nor extended time series. Computational demands manifest\\nduring both distribution learning in training and data genera-\\ntion in sampling phases, with the sampling process’s iterative\\nnature demanding numerous steps for quality output [Cui et\\nal., 2023]. For example, high-resolution IAD suffers from in-\\ncreased computational overhead due to data volume, model'),\n",
       " Document(metadata={'source': 'Docs/A Survey on Diffusion Models for Anomaly Detection.pdf', 'page': 6}, page_content='complexity, and the need to capture temporal dependencies\\n[Wyatt et al., 2022]. However, some researchers are actively\\nexploring solutions. One promising direction is faster sam-\\npling methods, such as progressive distillation and optimized\\nsampling schedules like align your steps, which aim to re-\\nduce sampling steps while maintaining quality [Salimans and\\nHo, 2021]. Another approach is model compression through\\ntechniques like pruning and quantization. Additionally, effi-\\ncient architectures, like[Cui et al., 2023] leveraging ER SDEs\\nfor faster sampling, and preconditioning methods offer fur-\\nther computational gains.\\nInterpretability and Explainability. Interpretability re-\\nmains a key challenge for DMAD [Katsuoka et al., 2024 ].\\nUnderstanding DM’s decision-making is crucial, especially\\nin critical applications. Visualizing anomaly scores,\\nlike spatially highlighting anomalous image regions as in\\nreconstruction-based methods [Yaoet al., 2025], becomes es-\\nsential. However, the iterative denoising process inherent in\\nDMs complicates interpretability. Explaining anomaly de-\\ntection requires identifying and explaining deviating features.\\nIntegrating DMs with explainable AI (xAI) techniques, such\\nas incorporating attention mechanisms or leveraging LLMs\\nfor textual/visual explanations [Wang et al., 2023b], offers a\\npromising research direction.\\nComplex Data Distributions. A key challenge in applying\\nDMAD lies in handling complex data distributions. Imbal-\\nanced datasets, where anomalies are rare, can bias DMs to-\\nwards the majority class [Yanget al., 2024a], hindering accu-\\nrate anomaly modeling. Similarly, multimodal datasets, rep-\\nresenting distinct normal behaviors, can confound DM learn-\\ning [Zuo et al., 2024 ], potentially misclassifying data from\\nless prominent modes. Noisy or missing data further compli-\\ncates DM training and inference [Choi et al., 2022], as dif-\\nferentiating true anomalies from data imperfections becomes\\ndifficult. However, potential solutions exist. Data augmen-\\ntation techniques can address class imbalance by generating\\nsynthetic minority class samples [Yang et al., 2024a ]. Ro-\\nbust training methods, such as using semi-unbalanced opti-\\nmal transport, can enhance DM resilience to noise and out-\\nliers [Dao et al., 2024]. Specialized architectures, potentially\\nincorporating mechanisms for handling missing data or mod-\\neling multiple modes [Xiao et al., 2023], and dynamic step\\nsize computation [Tebbe and Tayyub, 2024] could further im-\\nprove DM performance on complex distributions.\\nRobustness and Adversarial Attacks.Adversarial robust-\\nness is a critical concern for DMAD. Similar to other deep\\nlearning models, DMs are vulnerable to adversarial perturba-\\ntions, raising concerns about the reliability of diffusion-based\\nAD systems [Chen et al., 2024b ]. For example, [Kang et\\nal., 2025] demonstrates the potential of DMs for adversarial\\ndefense in classification, directly applying such methods to\\nAD can reduce anomaly detection rates. Specifically, the pu-\\nrification process may remove crucial anomaly signals along\\nwith noise. Additionally, adversarial examples exhibit mis-\\nalignment within DM manifolds, offering a potential detec-\\ntion avenue but requiring further investigation. The observed\\nrobustness differences between pixel-space diffusion models\\n(PDMs) and more vulnerable latent diffusion models (LDMs)\\n[Graham et al., 2023] further underscore the need to consider\\nspecific DM types. Consequently, future research should pri-\\noritize robust DM-based AD methods, including architectures\\nand training procedures that distinguish genuine anomalies\\nfrom adversarial noise. Promising directions include defense\\nstrategies like DIFFender[Kang et al., 2025], leveraging text-\\nguided diffusion and the adversarial anomaly perception phe-\\nnomenon, and incorporating insights from adversarial exam-\\nple behavior within DM manifolds.\\nEdge-Cloud Collaboration. Real-time DMAD faces sig-\\nnificant adoption barriers due to their substantial computa-\\ntional demands [Li et al., 2023 ]. Edge-cloud collaboration\\noffers a promising solution to this challenge by distribut-\\ning the workload between edge devices and cloud servers.\\nLightweight DMs deployed on edge devices perform initial\\nanomaly screening, while resource-intensive tasks like full\\nreconstructions are efficiently offloaded to cloud servers[Yan\\net al., 2024]. In addition, federated learning enables collabo-\\nrative model training across edge devices and the cloud with-\\nout sharing sensitive data, thereby enhancing generalization\\nand preserving privacy [Jin et al., 2024]. Dynamic DM parti-\\ntioning [Chen et al., 2024a] facilitates adaptive resource allo-\\ncation, optimizing performance based on network conditions\\nand computational demands. Strategic data placement and\\ndistributed DNN deployment principles further enhance sys-\\ntem efficiency. The integration of proactive detection mech-\\nanisms, exemplified by Maat [Lee et al., 2023b], proves par-\\nticularly valuable for time-critical applications in cloud mon-\\nitoring and AIOps environments.\\nIntegrating with Large Language Models. Integrating\\nDMs with LLMs offers a highly promising avenue for\\nenhancing anomaly detection, particularly by generating\\nhuman-interpretable explanations of detected anomalies and\\nincorporating rich contextual information [Kumar et al.,\\n2023]. For example, LLMs can leverage detailed textual de-\\nscriptions to provide context for observed fluctuations, dis-\\ntinguishing genuine anomalies from expected variations for\\nMAD [Capogrosso et al., 2024]. However, current LLM in-\\ntegration for anomaly detection faces a key challenge: effec-\\ntively representing and tokenizing temporal data. Existing\\ntokenizers, primarily designed for text, may not adequately\\ncapture the subtle nuances of numerical and temporal data,\\npotentially hindering performance [Li et al., 2024]. Conse-\\nquently, a critical research direction involves developing ef-\\nficient data representation techniques and specialized LLMs\\nfor anomaly detection to fully realize this synergistic ap-\\nproach’s potential [Tebbe and Tayyub, 2024].\\n6 Conclusion\\nIn this survey, we first introduce the core concepts of anomaly\\ndetection and diffusion models, providing a foundation for\\nunderstanding DMAD. Then, we systematically review exist-\\ning methodologies and their tasks across diverse data types,\\nincluding image, time series, and multimodal data. Further-\\nmore, we analyze representative approaches for each data\\ntype, highlighting their strengths and limitations. To promote\\nfurther research, we identify key challenges and promising\\nfuture directions, aiming to advance DMAD research and in-\\nspire innovative solutions for real-world applications.'),\n",
       " Document(metadata={'source': 'Docs/A Survey on Diffusion Models for Anomaly Detection.pdf', 'page': 7}, page_content='References\\n[Bercea et al., 2023] Cosmin I. Bercea, Michael Neumayr,\\nDaniel Rueckert, and Julia A. Schnabel. Mask, stitch,\\nand re-sample: Enhancing robustness and generalizability\\nin anomaly detection through automatic diffusion models.\\narXiv:2305.19643, 2023.\\n[Cao et al., 2024] Defu Cao, Wen Ye, and Yan Liu. Timedit:\\nGeneral-purpose diffusion transformers for time series\\nfoundation model. In ICMLW, 2024.\\n[Capogrosso et al., 2024] Luigi Capogrosso, Alvise\\nVivenza, Andrea Chiarini, Francesco Setti, and Marco\\nCristani. Exploiting multimodal latent diffusion models\\nfor accurate anomaly detection in industry 5.0. In xAI,\\nvolume 3762, pages 230–235, 2024.\\n[Chen et al., 2024a] Xiangchun Chen, Jiannong Cao, Yuvraj\\nSahni, Shan Jiang, and Zhixuan Liang. Dynamic task of-\\nfloading in edge computing based on dependency-aware\\nreinforcement learning. IEEE TCC, 12:594–608, 2024.\\n[Chen et al., 2024b] Yong Chen, Xuedong Li, Peng Hu,\\nDezhong Peng, and Xu Wang. Diffilter: Defending against\\nadversarial perturbations with diffusion filter. IEEE TIFS,\\n19:6779–6794, 2024.\\n[Cheng et al., 2024] Kai Cheng, Yaning Pan, Yang Liu, Xin-\\nhua Zeng, and Rui Feng. Denoising diffusion-augmented\\nhybrid video anomaly detection via reconstructing noised\\nframes. In IJCAI, volume 2, pages 695–703, 2024.\\n[Choi et al., 2022] Jooyoung Choi, Jungbeom Lee, Chaehun\\nShin, Sungwon Kim, Hyunwoo Kim, and Sungroh Yoon.\\nPerception prioritized training of diffusion models. In\\nCVPR, pages 11472–11481, 2022.\\n[Cui et al., 2023] Qinpeng Cui, Xinyi Zhang, Zongqing Lu,\\nand Qingmin Liao. Elucidating the solution space of ex-\\ntended reverse-time sde for diffusion models, 2023.\\n[Dao et al., 2024] Quan Dao, Binh Ta, Tung Pham, and Anh\\nTran. A high-quality robust diffusion framework for cor-\\nrupted dataset, 2024.\\n[Deveney et al., 2023] Teo Deveney, Jan Stanczuk,\\nLisa Maria Kreusser, Chris Budd, and Carola-Bibiane\\nSch¨onlieb. Closing the ode-sde gap in score-based\\ndiffusion models through the fokker-planck equation.\\narXiv:2311.15996, 2023.\\n[Fang et al., 2023] Fen Fang, Yun Liu, Ali Koksal, Qianli\\nXu, and Joo-Hwee Lim. Masked diffusion with task-\\nawareness for procedure planning in instructional videos.\\narXiv:2309.07409, 2023.\\n[Flaborea et al., 2023] Alessandro Flaborea, Luca Col-\\nlorone, Guido Maria D’Amely Di Melendugno, Stefano\\nD’Arrigo, Bardh Prenkaj, and Fabio Galasso. Multimodal\\nmotion conditioned diffusion model for skeleton-based\\nvideo anomaly detection. In ICCV, pages 1–9, 2023.\\n[Fontanella et al., 2024] Alessandro Fontanella, Grant Mair,\\nJoanna Wardlaw, Emanuele Trucco, and Amos Storkey.\\nDiffusion models for counterfactual generation and\\nanomaly detection in brain images. IEEE TMC, 2024.\\n[Graham et al., 2023] Mark S. Graham, Walter Hugo Lopez\\nPinaya, Paul Wright, Petru-Daniel Tudosiu, Yee H. Mah,\\nJames T. Teo, H. Rolf J ¨ager, David Werring, Parashkev\\nNachev, Sebastien Ourselin, and M. Jorge Cardoso. Unsu-\\npervised 3d out-of-distribution detection with latent diffu-\\nsion models. In MICCAI, pages 446–456, 2023.\\n[Han et al., 2024a] Jiashu Han, Shanshan Feng, Min Zhou,\\nXinyu Zhang, Yew Soon Ong, and Xutao Li. Diffusion\\nmodel in normal gathering latent space for time series\\nanomaly detection. InECML PKDD, volume 14943, pages\\n284–300, 2024.\\n[Han et al., 2024b] Yinbin Han, Meisam Razaviyayn, and\\nRenyuan Xu. Neural network-based score estimation in\\ndiffusion models: Optimization and generalization, 2024.\\n[Hu and Jin, 2023] Xianyao Hu and Congming Jin. An-\\nodode: Anomaly detection with diffusion ode, 2023.\\n[Hu et al., 2024a] Jie Hu, Yawen Huang, Yilin Lu, Guoyang\\nXie, Guannan Jiang, Yefeng Zheng, and Zhichao Lu.\\nAnomalyxfusion: Multi-modal anomaly synthesis with\\ndiffusion. arXiv:2404.19444, 2024.\\n[Hu et al., 2024b] Teng Hu, Jiangning Zhang, Ran Yi,\\nYuzhen Du, Xu Chen, Liang Liu, Yabiao Wang, and\\nChengjie Wang. Anomalydiffusion: Few-shot anomaly\\nimage generation with diffusion model. In AAAI, vol-\\nume 38, pages 8526–8534, 2024.\\n[Iqbal et al., 2024] Hasan Iqbal, Umar Khalid, Chen Chen,\\nand Jing Hua. Unsupervised anomaly detection in medical\\nimages using masked diffusion model. In MLMI, pages\\n372–381, 2024.\\n[Jin et al., 2024] Ming Jin, Huan Yee Koh, Qingsong Wen,\\nDaniele Zambon, Cesare Alippi, Geoffrey I. Webb, Irwin\\nKing, and Shirui Pan. A survey on graph neural networks\\nfor time series: Forecasting, classification, imputation, and\\nanomaly detection. IEEE TPAMI, 46(12):1–20, 2024.\\n[Kang et al., 2025] Caixin Kang, Yinpeng Dong, Zhengyi\\nWang, Shouwei Ruan, Yubo Chen, Hang Su, and Xingx-\\ning Wei. Diffender: Diffusion-based adversarial defense\\nagainst patch attacks. In ECCV, pages 130–147, 2025.\\n[Katsuoka et al., 2024] Teruyuki Katsuoka, Tomohiro Shi-\\nraishi, Daiki Miwa, V o Nguyen Le Duy, and Ichiro\\nTakeuchi. Statistical test on diffusion model-based\\nanomaly detection by selective inference, 2024.\\n[Kumar et al., 2023] Komal Kumar, Snehashis Chakraborty,\\nand Sudipta Roy. Self-supervised diffusion model for\\nanomaly segmentation in medical imaging. In PRMI, vol-\\nume 14301, pages 359–368, 2023.\\n[Le Lan and Dinh, 2021] Charline Le Lan and Laurent Dinh.\\nPerfect density models cannot guarantee anomaly detec-\\ntion. Entropy, 23:1690, 2021.\\n[Lee et al., 2023a] Chaejeong Lee, Jayoung Kim, and\\nNoseong Park. Codi: Co-evolving contrastive diffusion\\nmodels for mixed-type tabular synthesis. In ICML, pages\\n18940–18956, 2023.\\n[Lee et al., 2023b] Cheryl Lee, Tianyi Yang, Zhuangbin\\nChen, Yuxin Su, and Michael R. Lyu. Maat: Performance\\nmetric anomaly anticipation for cloud services with condi-\\ntional diffusion. In ASE, pages 116–128, 2023.\\n[Li et al., 2023] Jinpeng Li, Hanqun Cao, Jiaze Wang, Fu-\\nrui Liu, Qi Dou, Guangyong Chen, and Pheng-Ann Heng.\\nFast non-markovian diffusion model for weakly super-\\nvised anomaly detection in brain mr images. In MICCAI,\\nvolume 14224, pages 579–589, 2023.\\n[Li et al., 2024] Shu Li, Jiong Yu, Yi Lu, Guangqi Yang,\\nXusheng Du, and Su Liu. Self-supervised enhanced\\ndenoising diffusion for anomaly detection. Inf. Sci.,\\n669:120612, 2024.\\n[Liu et al., 2024a] Hao Liu, Lijun He, Miao Zhang, and Fan\\nLi. Vadiffusion: Compressed domain information guided\\nconditional diffusion for video anomaly detection. IEEE\\nTCSVT, 34:8398–8411, 2024.'),\n",
       " Document(metadata={'source': 'Docs/A Survey on Diffusion Models for Anomaly Detection.pdf', 'page': 8}, page_content='[Liu et al., 2024b] Yixin Liu, Thalaiyasingam Ajanthan,\\nHisham Husain, and Vu Nguyen. Self-supervision im-\\nproves diffusion models for tabular data imputation. In\\nCIKM, pages 1513–1522, 2024.\\n[Livernoche et al., 2023] Victor Livernoche, Vineet Jain,\\nYashar Hezaveh, and Siamak Ravanbakhsh. On diffusion\\nmodeling for anomaly detection. In ICLR, 2023.\\n[Luo, 2023] Weijian Luo. A comprehensive survey on\\nknowledge distillation of diffusion models, 2023.\\n[Naval Marimont et al., 2024] Sergio Naval Marimont,\\nVasilis Siomos, Matthew Baugh, Christos Tzelepis,\\nBernhard Kainz, and Giacomo Tarroni. Ensembled\\ncold-diffusion restorations for unsupervised anomaly\\ndetection. In MICCAI, pages 243–253, 2024.\\n[Pang et al., 2021] Guansong Pang, Chunhua Shen, Long-\\nbing Cao, and Anton Van Den Hengel. Deep learning for\\nanomaly detection: A review. ACM CSUR, 54(2):38:1–\\n38:38, March 2021.\\n[Salimans and Ho, 2021] Tim Salimans and Jonathan Ho.\\nProgressive distillation for fast sampling of diffusion mod-\\nels. In ICLR, 2021.\\n[Sheng et al., 2024] Xinyu Sheng, Shande Tuo, and\\nLu Wang. Surface anomaly detection and localization\\nwith diffusion-based reconstruction. In IJCNN, pages\\n1–8, 2024.\\n[Sui et al., 2024] Jialin Sui, Jinsong Yu, Yue Song, and Jian\\nZhang. Anomaly detection for telemetry time series using\\na denoising diffusion probabilistic model. IEEE Sens. J.,\\n24:16429–16439, 2024.\\n[Tebbe and Tayyub, 2024] Justin Tebbe and Jawad Tayyub.\\nDynamic addition of noise in a diffusion model for\\nanomaly detection. In CVPR, pages 3940–3949, 2024.\\n[Tur et al., 2023a] Anil Osman Tur, Nicola Dall’Asen, Cig-\\ndem Beyan, and Elisa Ricci. Exploring diffusion models\\nfor unsupervised video anomaly detection. In ICIP, pages\\n2540–2544, 2023.\\n[Tur et al., 2023b] Anil Osman Tur, Nicola Dall’Asen, Cig-\\ndem Beyan, and Elisa Ricci. Unsupervised video anomaly\\ndetection with diffusion models conditioned on compact\\nmotion representations. In ICIAP, pages 49–62, 2023.\\n[Wang and Vastola, 2023] Binxu Wang and John J. Vastola.\\nThe hidden linear structure in score-based models and its\\napplication. arXiv:2311.10892, 2023.\\n[Wang et al., 2023a] Chengsen Wang, Zirui Zhuang, Qi Qi,\\nJingyu Wang, Xingyu Wang, Haifeng Sun, and Jianxin\\nLiao. Drift doesn’t matter: Dynamic decomposition with\\ndiffusion reconstruction for unstable multivariate time se-\\nries anomaly detection. In NeurIPS, volume 36, pages\\n10758–10774, 2023.\\n[Wang et al., 2023b] He Wang, Longquan Dai, Jinglin Tong,\\nand Yan Zhai. Odd: One-class anomaly detection via the\\ndiffusion model. In ICIP, pages 3000–3004, 2023.\\n[Wang et al., 2023c] Wenjie Wang, Yiyan Xu, Fuli Feng,\\nXinyu Lin, Xiangnan He, and Tat-Seng Chua. Diffusion\\nrecommender model. In SIGIR, pages 832–841, 2023.\\n[Wang et al., 2023d] Zhiqiang Wang, Xiaojing Gu, Jingyu\\nHu, and Xingsheng Gu. Ensemble anomaly score for video\\nanomaly detection using denoise diffusion model and mo-\\ntion filters. Neurocomputing, 553:126589, 2023.\\n[Wu et al., 2024] Di Wu, Shicai Fan, Xue Zhou, Li Yu,\\nYuzhong Deng, Jianxiao Zou, and Baihong Lin. Unsu-\\npervised anomaly detection via masked diffusion posterior\\nsampling. arXiv:2404.17900, 2024.\\n[Wyatt et al., 2022] Julian Wyatt, Adam Leach, Sebastian M.\\nSchmon, and Chris G. Willcocks. Anoddpm: Anomaly de-\\ntection with denoising diffusion probabilistic models using\\nsimplex noise. In CVPR, pages 650–656, 2022.\\n[Xiao et al., 2023] Chunjing Xiao, Zehua Gou, Wenxin Tai,\\nKunpeng Zhang, and Fan Zhou. Imputation-based\\ntime-series anomaly detection with conditional weight-\\nincremental diffusion models. In KDD, pages 1–9, 2023.\\n[Xu et al., 2023] Haohao Xu, Shuchang Xu, and Wenzhen\\nYang. Unsupervised industrial anomaly detection with\\ndiffusion models. J. Vis. Commun. Image Represent.,\\n97:103983, 2023.\\n[Yan et al., 2023] Cheng Yan, Shiyu Zhang, Yang Liu,\\nGuansong Pang, and Wenjun Wang. Feature prediction\\ndiffusion model for video anomaly detection. In ICCV,\\npages 5504–5514, 2023.\\n[Yan et al., 2024] Chenqian Yan, Songwei Liu, Hongjian\\nLiu, Xurui Peng, Xiaojian Wang, Fangmin Chen, Lean Fu,\\nand Xing Mei. Hybrid sd: Edge-cloud collaborative infer-\\nence for stable diffusion models, 2024.\\n[Yang et al., 2024a] Xiongyan Yang, Tianyi Ye, Xianfeng\\nYuan, Weijie Zhu, Xiaoxue Mei, and Fengyu Zhou. A\\nnovel data augmentation method based on denoising dif-\\nfusion probabilistic model for fault diagnosis under imbal-\\nanced data. IEEE TII, 20:7820–7831, 2024.\\n[Yang et al., 2024b] Yiyuan Yang, Ming Jin, Haomin Wen,\\nChaoli Zhang, Yuxuan Liang, Lintao Ma, Yi Wang,\\nChenghao Liu, Bin Yang, Zenglin Xu, Jiang Bian, Shirui\\nPan, and Qingsong Wen. A survey on diffusion models for\\ntime series and spatio-temporal data, 2024.\\n[Yao et al., 2025] Hang Yao, Ming Liu, Zhicun Yin, Zifei\\nYan, Xiaopeng Hong, and Wangmeng Zuo. Glad: To-\\nwards better reconstruction with global and local adaptive\\ndiffusion models for unsupervised anomaly detection. In\\nECCV, pages 1–17, 2025.\\n[Yoon et al., 2023] Sangwoong Yoon, Young-Uk Jin, Yung-\\nKyun Noh, and Frank Park. Energy-based models for\\nanomaly detection: A manifold diffusion recovery ap-\\nproach. In NeurIPS, volume 36, pages 1–21, 2023.\\n[Zhan et al., 2024] Jiawei Zhan, Jinxiang Lai, Bin-Bin Gao,\\nJun Liu, Xiaochen Chen, and Chengjie Wang. Enhanc-\\ning multi-class anomaly detection via diffusion refinement\\nwith dual conditioning. arXiv:2407.01905, 2024.\\n[Zhang and Pilanci, 2024] Fangzhao Zhang and Mert Pi-\\nlanci. Analyzing neural network-based generative diffu-\\nsion models through convex optimization, 2024.\\n[Zhang et al., 2023] Hui Zhang, Zheng Wang, Zuxuan Wu,\\nand Yu-Gang Jiang. Diffusionad: Norm-guided one-step\\ndenoising diffusion for anomaly detection, 2023.\\n[Zhang et al., 2024] Menghao Zhang, Jingyu Wang, Qi Qi,\\nPengfei Ren, Haifeng Sun, Zirui Zhuang, Lei Zhang, and\\nJianxin Liao. Safeguarding sustainable cities: Unsuper-\\nvised video anomaly detection through diffusion-based la-\\ntent pattern learning. In IJCAI, volume 8, pages 7572–\\n7580, 2024.\\n[Zhu et al., 2024] Aoni Zhu, Wenjun Wang, and Cheng Yan.\\nFlow-guided diffusion autoencoder for unsupervised video\\nanomaly detection. In PRCV, volume 14430, pages 183–\\n194, 2024.\\n[Zuo et al., 2024] Haiwei Zuo, Aiqun Zhu, Yanping Zhu,\\nYinping Liao, Shiman Li, and Yun Chen. Unsupervised\\ndiffusion based anomaly detection for time series. APIN,\\n54:8968–8981, 2024.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG\n",
    "\n",
    "**Retrieval-Augmented Generation (RAG)** models are an innovative approach in the field of artificial intelligence, aiming to combine the power of text generation models with the efficiency of search engines. Unlike traditional text generation models that rely solely on knowledge acquired during training, RAGs integrate a real-time information retrieval phase from an external database or a corpus of documents.\n",
    "\n",
    "This architecture is based on two main steps:\n",
    "1. **Retrieval**: The model searches a large database or a set of relevant documents based on the user's query.\n",
    "2. **Generation**: The model uses the retrieved information to generate a more precise and informed answer, combining both the pre-existing context and the new data retrieved.\n",
    "\n",
    "RAGs are particularly useful in contexts where information is changing rapidly or where the knowledge base is too large to be fully included in the model. For example, in chatbots or question-answering (QA) systems, this approach can improve the relevance of answers and reduce bias or errors related to missing or outdated information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agentic RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
